import React, {
  useEffect,
  useMemo,
  useRef,
  useState,
  useCallback,
} from "react";
import { useNavigate } from "react-router-dom";
import BackButton from "../components/BackButton";
import AudioSpectrum from "../components/AudioSpectrum";
import {
  Page,
  Title,
  RecognizedText,
  ExampleBox,
  ExampleHeading,
  ExampleGray,
  DoneButton,
} from "./VoiceRecognize.styles";
import { AudioRecorder, getAudioDuration } from "../utils/audioUtils";
import { getSettings } from "../utils/settingsUtils";
import { addToHistory } from "../utils/historyUtils";
import { sttService } from "../services/api";

function VoiceRecognize() {
  const navigate = useNavigate();
  const recorderRef = useRef(null);
  const [isRecording, setIsRecording] = useState(false);
  const [recognized, setRecognized] = useState("");
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [voiceDetected, setVoiceDetected] = useState(false); // eslint-disable-line no-unused-vars
  const interimTimerRef = useRef(null);
  const snapshotInFlightRef = useRef(false);

  const language = useMemo(() => getSettings().defaultLanguage || "ko", []);
  const MIN_DURATION_SEC = 1.0; // STT ì „ì†¡ì„ ìœ„í•œ ìµœì†Œ ë…¹ìŒ ì‹œê°„

  function extractTextFromSttResponse(raw) {
    if (!raw) return "";

    // ë¡œê·¸ ì¶œë ¥ìœ¼ë¡œ ë””ë²„ê¹…
    console.log("ğŸ” STT ì‘ë‹µ ë¶„ì„:", raw);

    // ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°: { success: true/false, text: "...", error: "..." }
    if (typeof raw === "object") {
      // successê°€ falseì¸ ê²½ìš° ì—ëŸ¬ ì²˜ë¦¬
      if (raw.success === false) {
        throw new Error(raw.error || "STT ë³€í™˜ ì‹¤íŒ¨");
      }

      // successê°€ trueì¸ ê²½ìš° text ì¶”ì¶œ
      if (raw.success === true && typeof raw.text === "string") {
        return raw.text.trim();
      }
    }

    // ê¸°ì¡´ ë‹¤ë¥¸ ì‘ë‹µ êµ¬ì¡° ì§€ì› (í•˜ìœ„ í˜¸í™˜ì„±)
    if (typeof raw.text === "string" && raw.text.trim()) return raw.text;
    if (typeof raw.transcript === "string" && raw.transcript.trim())
      return raw.transcript;
    if (typeof raw.recognized_text === "string" && raw.recognized_text.trim())
      return raw.recognized_text;
    if (typeof raw.recognizedText === "string" && raw.recognizedText.trim())
      return raw.recognizedText;

    // ì¤‘ì²© êµ¬ì¡°ë“¤
    const nested = raw.result || raw.data || raw.payload || {};
    if (typeof nested.text === "string" && nested.text.trim())
      return nested.text;
    if (typeof nested.transcript === "string" && nested.transcript.trim())
      return nested.transcript;

    // ë°°ì—´ í˜•íƒœ (ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)
    if (Array.isArray(raw.segments)) {
      const joined = raw.segments
        .map((s) => s.text || s.transcript || "")
        .filter(Boolean)
        .join(" ")
        .trim();
      if (joined) return joined;
    }

    // ì‘ë‹µì´ ë¬¸ìì—´ì¸ ê²½ìš°
    if (typeof raw === "string" && raw.trim()) return raw;

    return "";
  }

  async function toggleRecording() {
    setError("");
    // ì•ˆì „ ì¥ì¹˜: ì™„ë£Œ ì‹œ ì„ì‹œ ì „ì†¡ íƒ€ì´ë¨¸ ì¤‘ì§€
    if (interimTimerRef.current) {
      clearInterval(interimTimerRef.current);
      interimTimerRef.current = null;
    }
    if (!recorderRef.current) {
      recorderRef.current = new AudioRecorder();
      const init = await recorderRef.current.initializeRecording();
      if (!init.success) {
        setError(init.error || "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨");
        return;
      }
    }

    if (!isRecording) {
      try {
        recorderRef.current.startRecording();
        setIsRecording(true);
      } catch (e) {
        setError(e.message);
      }
    } else {
      try {
        setLoading(true);
        const audioFile = await recorderRef.current.stopRecording();
        setIsRecording(false);
        if (!audioFile) {
          setError("ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨");
          setLoading(false);
          return;
        }
        console.log("ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´:");
        console.log(`  - íŒŒì¼ëª…: ${audioFile.name}`);
        console.log(`  - í¬ê¸°: ${audioFile.size} bytes`);
        console.log(`  - íƒ€ì…: ${audioFile.type}`);
        console.log(`  - ì–¸ì–´: ${language}`);

        // Duration ì²´í¬ (Infinityë©´ ê±´ë„ˆë›°ê¸°)
        const duration = await getAudioDuration(audioFile);
        console.log(`  - ê³„ì‚°ëœ ì¬ìƒì‹œê°„: ${duration}ì´ˆ`);

        if (Number.isFinite(duration) && duration <= 0) {
          setError("ìœ íš¨í•œ ìŒì„± ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤.");
          setLoading(false);
          return;
        }

        if (Number.isFinite(duration) && duration < MIN_DURATION_SEC) {
          console.warn(
            `âš ï¸ ë…¹ìŒ ì‹œê°„ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ ${MIN_DURATION_SEC}ì´ˆ ì´ìƒ ë…¹ìŒí•´ì£¼ì„¸ìš”.`
          );
          setError(
            `ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ ${MIN_DURATION_SEC}ì´ˆ ì´ìƒ ë§ì”€í•´ì£¼ì„¸ìš”.`
          );
          setLoading(false);
          return;
        }

        // STT API í˜¸ì¶œ
        console.log("ğŸŒ STT API í˜¸ì¶œ ì‹œì‘...");
        const data = await sttService.convertSpeechToText(audioFile, language);
        console.log("ğŸ“¥ STT API ì‘ë‹µ:", data);

        const text = extractTextFromSttResponse(data);
        console.log("âœ… ì¶”ì¶œëœ í…ìŠ¤íŠ¸:", text);

        setRecognized(text);
        if (text) {
          addToHistory(
            {
              text,
              confidence: data?.confidence ?? null,
              language: language, // ë°±ì—”ë“œì—ì„œ ì–¸ì–´ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìš”ì²­í•œ ì–¸ì–´ ì‚¬ìš©
              processingTime: null, // ë°±ì—”ë“œì—ì„œ ì²˜ë¦¬ ì‹œê°„ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
            },
            audioFile.name,
            audioFile.size
          );
          console.log("âœ… íˆìŠ¤í† ë¦¬ì— ì €ì¥ ì™„ë£Œ");
        } else {
          console.warn(
            "âš ï¸ í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
          );
          setError(
            "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•˜ê±°ë‚˜ ë” ê¸¸ê²Œ ë…¹ìŒí•´ë³´ì„¸ìš”."
          );
        }
      } catch (e) {
        console.error("âŒ ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e);
        setError(e.message || "ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      } finally {
        setLoading(false);
      }
    }
  }

  // 2ì´ˆë§ˆë‹¤ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•´ì„œ STT ì „ì†¡ (ë…¹ìŒ ìœ ì§€)
  const sendInterimSnapshot = useCallback(async () => {
    if (!recorderRef.current || snapshotInFlightRef.current) return;
    snapshotInFlightRef.current = true;
    try {
      const snapshotFile = await recorderRef.current.getSnapshotFile(
        "recording-interim"
      );
      if (!snapshotFile || snapshotFile.size < 2000) return; // ë„ˆë¬´ ì‘ì€ ê²½ìš° ìƒëµ

      const data = await sttService.convertSpeechToText(snapshotFile, language);
      const text = extractTextFromSttResponse(data);
      if (text) setRecognized(text);
    } catch (err) {
      // ì„ì‹œ ì „ì†¡ ì‹¤íŒ¨ëŠ” UI ì—ëŸ¬ë¡œ ë…¸ì¶œí•˜ì§€ ì•ŠìŒ
      console.warn("Interim STT failed:", err?.message || err);
    } finally {
      snapshotInFlightRef.current = false;
    }
  }, [language]);

  // í˜ì´ì§€ ì§„ì… ì‹œ ìë™ ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    let isCancelled = false;

    async function startOnMount() {
      try {
        if (!recorderRef.current) {
          const recorder = new AudioRecorder();
          const init = await recorder.initializeRecording();
          if (!init.success) {
            if (!isCancelled) setError(init.error || "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨");
            return;
          }
          recorderRef.current = recorder;
        }

        // ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        if (!isCancelled) {
          recorderRef.current.startRecording();
          setIsRecording(true);
        }
      } catch (e) {
        if (!isCancelled)
          setError(e.message || "ë…¹ìŒ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      }
    }

    startOnMount();

    return () => {
      isCancelled = true;
    };
  }, []);

  // ë…¹ìŒ ìƒíƒœì— ë”°ë¼ 2ì´ˆ ê°„ê²© ìŠ¤ëƒ…ìƒ· íƒ€ì´ë¨¸ ê´€ë¦¬
  useEffect(() => {
    if (isRecording) {
      if (interimTimerRef.current) clearInterval(interimTimerRef.current);
      interimTimerRef.current = setInterval(() => {
        // ìŒì„±ì´ ê°ì§€ë  ë•Œë§Œ ì „ì†¡í•˜ê³  ì‹¶ë‹¤ë©´ voiceDetectedë¥¼ ì²´í¬ ê°€ëŠ¥
        sendInterimSnapshot();
      }, 3000);
    } else if (interimTimerRef.current) {
      clearInterval(interimTimerRef.current);
      interimTimerRef.current = null;
    }
    return () => {
      if (interimTimerRef.current) {
        clearInterval(interimTimerRef.current);
        interimTimerRef.current = null;
      }
    };
  }, [isRecording, sendInterimSnapshot]);

  useEffect(() => {
    return () => {
      if (recorderRef.current) {
        recorderRef.current.cancelRecording();
        recorderRef.current.cleanup();
      }
    };
  }, []);

  // ìŠ¤í™íŠ¸ëŸ¼ ë¡œì§ì€ ì»´í¬ë„ŒíŠ¸ë¡œ ë¶„ë¦¬ë¨

  return (
    <Page>
      <Title>
        {loading ? "ë³€í™˜ ì¤‘..." : isRecording ? "ì¸ì‹ ì¤‘..." : "ìŒì„± ì£¼ë¬¸"}
      </Title>

      {/* ì˜¤ë””ì˜¤ ìŠ¤í™íŠ¸ëŸ¼ */}
      <AudioSpectrum
        stream={recorderRef.current?.getStream?.()}
        active={isRecording}
        width={475}
        height={165}
        style={{ position: "absolute", left: 483, top: 253 }}
        onVoiceDetected={(v) =>
          setVoiceDetected((prev) => (prev !== v ? v : prev))
        }
      />

      <ExampleBox>
        <ExampleHeading>ì˜ˆì‹œ ë¬¸ì¥</ExampleHeading>
        <ExampleGray>â€œì•„ì´ìŠ¤ ì•„ë©”ë¦¬ì¹´ë…¸ 1ì” í¬ì¥â€</ExampleGray>
      </ExampleBox>

      <RecognizedText>{recognized ? `â€œ${recognized}â€` : ""}</RecognizedText>

      {/* ìë™ ì‹œì‘ìœ¼ë¡œ ì¤‘ì•™ í† ê¸€ ë²„íŠ¼ì€ ì œê±° */}

      <BackButton onClick={() => navigate(-1)} />
      <DoneButton
        disabled={loading}
        onClick={() => {
          if (isRecording) {
            // ë…¹ìŒ ì¤‘ì§€ ë° STT ì²˜ë¦¬
            toggleRecording();
          } else {
            // ì´ë¯¸ ë…¹ìŒì´ ì¤‘ì§€ëœ ê²½ìš° ì´ì „ í™”ë©´ìœ¼ë¡œ
            navigate(-1);
          }
        }}
      >
        ì™„ë£Œ
      </DoneButton>

      {error && (
        <div
          style={{
            position: "absolute",
            left: 334,
            top: 820,
            color: "#c0392b",
            fontSize: 20,
          }}
        >
          {error}
        </div>
      )}
    </Page>
  );
}

export default VoiceRecognize;
