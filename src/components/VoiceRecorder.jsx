import React, { useCallback, useEffect, useRef, useState } from "react";
import { AudioRecorder, getAudioDuration } from "../utils/audioUtils";
import { addToHistory } from "../utils/historyUtils";
import { sttService } from "../services/api";

/**
 * A render-prop React component that manages live audio recording and speech-to-text (STT) processing.
 *
 * Starts recording automatically on mount, takes interim audio snapshots while recording (every ~3s)
 * to provide live/interim recognition updates, and performs a final STT request when recording is stopped.
 * Exposes recording state and controls to children via a render function.
 *
 * Side effects:
 * - Initializes and controls an AudioRecorder instance.
 * - Calls sttService to convert audio (interim snapshots and final audio) to text.
 * - Persists successful final transcriptions to history via addToHistory.
 * - Cleans up recorder resources on unmount.
 *
 * @param {string} language - BCP-47 style language code used for STT requests (e.g., "en-US", "ko-KR").
 * @param {function({ isRecording: boolean, loading: boolean, error: string, stream: MediaStream | undefined, recognized: string, toggleRecording: function }): any} children
 *        Render-prop function that receives the component API:
 *        - isRecording: true when recording is active.
 *        - loading: true while final STT processing is in progress.
 *        - error: user-facing error message, empty when none.
 *        - stream: the MediaStream from the recorder (if available).
 *        - recognized: latest interim or final recognized text.
 *        - toggleRecording: function to start/stop recording and trigger final STT on stop.
 * @returns {any} The result of calling the `children` render function.
 */
function VoiceRecorder({ language, children }) {
  const recorderRef = useRef(null);
  const interimTimerRef = useRef(null);
  const snapshotInFlightRef = useRef(false);

  const [isRecording, setIsRecording] = useState(false);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [recognized, setRecognized] = useState("");

  const MIN_DURATION_SEC = 1.0;

  function extractTextFromSttResponse(raw) {
    if (!raw) return "";
    if (typeof raw === "object") {
      if (raw.success === false) {
        throw new Error(raw.error || "STT ë³€í™˜ ì‹¤íŒ¨");
      }
      if (raw.success === true && typeof raw.text === "string") {
        return raw.text.trim();
      }
    }
    if (typeof raw?.text === "string" && raw.text.trim()) return raw.text;
    if (typeof raw?.transcript === "string" && raw.transcript.trim())
      return raw.transcript;
    if (typeof raw?.recognized_text === "string" && raw.recognized_text.trim())
      return raw.recognized_text;
    if (typeof raw?.recognizedText === "string" && raw.recognizedText.trim())
      return raw.recognizedText;
    const nested = raw?.result || raw?.data || raw?.payload || {};
    if (typeof nested.text === "string" && nested.text.trim())
      return nested.text;
    if (typeof nested.transcript === "string" && nested.transcript.trim())
      return nested.transcript;
    if (Array.isArray(raw?.segments)) {
      const joined = raw.segments
        .map((s) => s.text || s.transcript || "")
        .filter(Boolean)
        .join(" ")
        .trim();
      if (joined) return joined;
    }
    if (typeof raw === "string" && raw.trim()) return raw;
    return "";
  }

  const sendInterimSnapshot = useCallback(async () => {
    if (!recorderRef.current || snapshotInFlightRef.current) return;
    snapshotInFlightRef.current = true;
    try {
      const snapshotFile = await recorderRef.current.getSnapshotFile(
        "recording-interim"
      );
      if (!snapshotFile || snapshotFile.size < 2000) return;
      const data = await sttService.convertSpeechToText(snapshotFile, language);
      const text = extractTextFromSttResponse(data);
      if (text) {
        setRecognized(text);
      }
    } catch {
      // ignore interim errors
    } finally {
      snapshotInFlightRef.current = false;
    }
  }, [language]);

  async function toggleRecording() {
    setError("");
    if (interimTimerRef.current) {
      clearInterval(interimTimerRef.current);
      interimTimerRef.current = null;
    }
    if (!recorderRef.current) {
      recorderRef.current = new AudioRecorder();
      const init = await recorderRef.current.initializeRecording();
      if (!init.success) {
        setError(init.error || "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨");
        return;
      }
    }

    if (!isRecording) {
      try {
        recorderRef.current.startRecording();
        setIsRecording(true);
      } catch (e) {
        setError(e.message);
      }
    } else {
      try {
        setLoading(true);
        const audioFile = await recorderRef.current.stopRecording();
        setIsRecording(false);
        if (!audioFile) {
          setError("ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨");
          setLoading(false);
          return;
        }
        console.log("ðŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´:");
        console.log(`  - íŒŒì¼ëª…: ${audioFile.name}`);
        console.log(`  - í¬ê¸°: ${audioFile.size} bytes`);
        console.log(`  - íƒ€ìž…: ${audioFile.type}`);
        console.log(`  - ì–¸ì–´: ${language}`);

        const duration = await getAudioDuration(audioFile);
        console.log(`  - ê³„ì‚°ëœ ìž¬ìƒì‹œê°„: ${duration}ì´ˆ`);

        if (Number.isFinite(duration) && duration <= 0) {
          setError("ìœ íš¨í•œ ìŒì„± ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤.");
          setLoading(false);
          return;
        }

        if (Number.isFinite(duration) && duration < MIN_DURATION_SEC) {
          console.warn(
            `âš ï¸ ë…¹ìŒ ì‹œê°„ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ ${MIN_DURATION_SEC}ì´ˆ ì´ìƒ ë…¹ìŒí•´ì£¼ì„¸ìš”.`
          );
          setError(
            `ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ ${MIN_DURATION_SEC}ì´ˆ ì´ìƒ ë§ì”€í•´ì£¼ì„¸ìš”.`
          );
          setLoading(false);
          return;
        }

        console.log("ðŸŒ STT API í˜¸ì¶œ ì‹œìž‘...");
        const data = await sttService.convertSpeechToText(audioFile, language);
        console.log("ðŸ“¥ STT API ì‘ë‹µ:", data);

        const text = extractTextFromSttResponse(data);
        console.log("âœ… ì¶”ì¶œëœ í…ìŠ¤íŠ¸:", text);

        setRecognized(text);
        if (text) {
          addToHistory(
            {
              text,
              confidence: data?.confidence ?? null,
              language: language,
              processingTime: null,
            },
            audioFile.name,
            audioFile.size
          );
          console.log("âœ… ížˆìŠ¤í† ë¦¬ì— ì €ìž¥ ì™„ë£Œ");
        } else {
          console.warn(
            "âš ï¸ í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
          );
          setError(
            "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•˜ê±°ë‚˜ ë” ê¸¸ê²Œ ë…¹ìŒí•´ë³´ì„¸ìš”."
          );
        }
      } catch (e) {
        console.error("âŒ ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e);
        setError(e.message || "ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      } finally {
        setLoading(false);
      }
    }
  }

  useEffect(() => {
    let isCancelled = false;
    async function startOnMount() {
      try {
        if (!recorderRef.current) {
          const recorder = new AudioRecorder();
          const init = await recorder.initializeRecording();
          if (!init.success) {
            if (!isCancelled) setError(init.error || "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨");
            return;
          }
          recorderRef.current = recorder;
        }
        if (!isCancelled) {
          recorderRef.current.startRecording();
          setIsRecording(true);
        }
      } catch (e) {
        if (!isCancelled)
          setError(e?.message || "ë…¹ìŒ ì‹œìž‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      }
    }
    startOnMount();
    return () => {
      isCancelled = true;
    };
  }, []);

  useEffect(() => {
    if (isRecording) {
      if (interimTimerRef.current) clearInterval(interimTimerRef.current);
      interimTimerRef.current = setInterval(() => {
        sendInterimSnapshot();
      }, 3000);
    } else if (interimTimerRef.current) {
      clearInterval(interimTimerRef.current);
      interimTimerRef.current = null;
    }
    return () => {
      if (interimTimerRef.current) {
        clearInterval(interimTimerRef.current);
        interimTimerRef.current = null;
      }
    };
  }, [isRecording, sendInterimSnapshot]);

  useEffect(() => {
    return () => {
      if (recorderRef.current) {
        try {
          recorderRef.current.cancelRecording();
          recorderRef.current.cleanup();
        } catch {
          // ignore cleanup errors
        }
      }
    };
  }, []);

  const stream = recorderRef.current?.getStream?.();

  return children({
    isRecording,
    loading,
    error,
    stream,
    recognized,
    toggleRecording,
  });
}

export default VoiceRecorder;
