import React, { useCallback, useEffect, useRef, useState } from "react";
import { AudioRecorder, getAudioDuration } from "../utils/audioUtils";
import { addToHistory } from "../utils/historyUtils";
import { sttService } from "../services/api";

function VoiceRecorder({
  language,
  children,
  disableInterim = false,
  autoStart = true,
  onRecognized,
}) {
  const recorderRef = useRef(null);
  const interimTimerRef = useRef(null);
  const snapshotInFlightRef = useRef(false);

  const [isRecording, setIsRecording] = useState(false);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [recognized, setRecognized] = useState("");

  const MIN_DURATION_SEC = 0.5;

  function extractTextFromSttResponse(raw) {
    if (!raw) return "";
    if (typeof raw === "object") {
      if (raw.success === false) {
        throw new Error(raw.error || "STT ë³€í™˜ ì‹¤íŒ¨");
      }
      if (raw.success === true && typeof raw.text === "string") {
        return raw.text.trim();
      }
    }
    if (typeof raw?.text === "string" && raw.text.trim()) return raw.text;
    if (typeof raw?.transcript === "string" && raw.transcript.trim())
      return raw.transcript;
    if (typeof raw?.recognized_text === "string" && raw.recognized_text.trim())
      return raw.recognized_text;
    if (typeof raw?.recognizedText === "string" && raw.recognizedText.trim())
      return raw.recognizedText;
    const nested = raw?.result || raw?.data || raw?.payload || {};
    if (typeof nested.text === "string" && nested.text.trim())
      return nested.text;
    if (typeof nested.transcript === "string" && nested.transcript.trim())
      return nested.transcript;
    if (Array.isArray(raw?.segments)) {
      const joined = raw.segments
        .map((s) => s.text || s.transcript || "")
        .filter(Boolean)
        .join(" ")
        .trim();
      if (joined) return joined;
    }
    if (typeof raw === "string" && raw.trim()) return raw;
    return "";
  }

  const sendInterimSnapshot = useCallback(async () => {
    if (!recorderRef.current || snapshotInFlightRef.current) return;
    snapshotInFlightRef.current = true;
    try {
      const snapshotFile = await recorderRef.current.getSnapshotFile(
        "recording-interim"
      );
      if (!snapshotFile || snapshotFile.size < 2000) return;
      const data = await sttService.convertSpeechToText(snapshotFile, language);
      const text = extractTextFromSttResponse(data);
      if (text) {
        setRecognized(text);
        if (typeof onRecognized === "function") {
          try {
            onRecognized(text);
          } catch {
            /* no-op */
          }
        }
      }
    } catch {
      // ignore interim errors
    } finally {
      snapshotInFlightRef.current = false;
    }
  }, [language, onRecognized]);

  async function toggleRecording() {
    setError("");
    if (interimTimerRef.current) {
      clearInterval(interimTimerRef.current);
      interimTimerRef.current = null;
    }
    if (!recorderRef.current) {
      recorderRef.current = new AudioRecorder();
      const init = await recorderRef.current.initializeRecording();
      if (!init.success) {
        setError(init.error || "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨");
        return;
      }
    }

    if (!isRecording) {
      try {
        recorderRef.current.startRecording();
        setIsRecording(true);
      } catch (e) {
        setError(e.message);
      }
    } else {
      try {
        setLoading(true);
        console.log("ðŸ›‘ ë…¹ìŒ ì¤‘ì§€ ì‹œìž‘...");
        const audioFile = await recorderRef.current.stopRecording();
        setIsRecording(false);

        console.log("ðŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ê²°ê³¼:", audioFile);

        if (!audioFile) {
          console.error("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì´ null ë˜ëŠ” undefinedìž…ë‹ˆë‹¤.");
          setError("ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.");
          setLoading(false);
          return;
        }

        if (audioFile.size === 0) {
          console.error("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸°ê°€ 0ë°”ì´íŠ¸ìž…ë‹ˆë‹¤.");
          setError("ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: ë…¹ìŒ ë°ì´í„°ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.");
          setLoading(false);
          return;
        }

        console.log("ðŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´:");
        console.log(`  - íŒŒì¼ëª…: ${audioFile.name}`);
        console.log(`  - í¬ê¸°: ${audioFile.size} bytes`);
        console.log(`  - íƒ€ìž…: ${audioFile.type}`);
        console.log(`  - ì–¸ì–´: ${language}`);

        const duration = await getAudioDuration(audioFile);
        console.log(`  - ê³„ì‚°ëœ ìž¬ìƒì‹œê°„: ${duration}ì´ˆ`);

        if (Number.isFinite(duration) && duration <= 0) {
          setError("ìœ íš¨í•œ ìŒì„± ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤.");
          setLoading(false);
          return;
        }

        if (Number.isFinite(duration) && duration < MIN_DURATION_SEC) {
          console.warn(
            `âš ï¸ ë…¹ìŒ ì‹œê°„ì´ ì§§ìŠµë‹ˆë‹¤ (${duration.toFixed(
              2
            )}ì´ˆ). ìµœì†Œ ${MIN_DURATION_SEC}ì´ˆ ê¶Œìž¥ë©ë‹ˆë‹¤.`
          );
          // ì§§ì€ ë…¹ìŒë„ í—ˆìš©í•˜ë˜ ê²½ê³ ë§Œ í‘œì‹œ
          console.log("ðŸ“¤ ì§§ì€ ë…¹ìŒì´ì§€ë§Œ STT ì²˜ë¦¬ë¥¼ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.");
        }

        console.log("ðŸŒ STT API í˜¸ì¶œ ì‹œìž‘...");
        const data = await sttService.convertSpeechToText(audioFile, language);
        console.log("ðŸ“¥ STT API ì‘ë‹µ:", data);

        const text = extractTextFromSttResponse(data);
        console.log("âœ… ì¶”ì¶œëœ í…ìŠ¤íŠ¸:", text);

        setRecognized(text);
        if (text && typeof onRecognized === "function") {
          try {
            onRecognized(text);
          } catch {
            /* no-op */
          }
        }
        if (text) {
          addToHistory(
            {
              text,
              confidence: data?.confidence ?? null,
              language: language,
              processingTime: null,
            },
            audioFile.name,
            audioFile.size
          );
          console.log("âœ… ížˆìŠ¤í† ë¦¬ì— ì €ìž¥ ì™„ë£Œ");
        } else {
          console.warn(
            "âš ï¸ í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
          );
          setError(
            "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•˜ê±°ë‚˜ ë” ê¸¸ê²Œ ë…¹ìŒí•´ë³´ì„¸ìš”."
          );
        }
      } catch (e) {
        console.error("âŒ ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e);
        setError(e.message || "ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      } finally {
        setLoading(false);
      }
    }
  }

  useEffect(() => {
    let isCancelled = false;
    async function startOnMount() {
      try {
        if (!recorderRef.current) {
          const recorder = new AudioRecorder();
          const init = await recorder.initializeRecording();
          if (!init.success) {
            if (!isCancelled) setError(init.error || "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨");
            return;
          }
          recorderRef.current = recorder;
        }
        if (!isCancelled && autoStart) {
          recorderRef.current.startRecording();
          setIsRecording(true);
        }
      } catch (e) {
        if (!isCancelled)
          setError(e?.message || "ë…¹ìŒ ì‹œìž‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      }
    }
    startOnMount();
    return () => {
      isCancelled = true;
    };
  }, [autoStart]);

  useEffect(() => {
    // disableInterimì´ trueë©´ ì¤‘ê°„ ìŠ¤ëƒ…ìƒ·ì„ ë¹„í™œì„±í™”
    if (isRecording && !disableInterim) {
      if (interimTimerRef.current) clearInterval(interimTimerRef.current);
      interimTimerRef.current = setInterval(() => {
        sendInterimSnapshot();
      }, 3000);
    } else if (interimTimerRef.current) {
      clearInterval(interimTimerRef.current);
      interimTimerRef.current = null;
    }
    return () => {
      if (interimTimerRef.current) {
        clearInterval(interimTimerRef.current);
        interimTimerRef.current = null;
      }
    };
  }, [isRecording, sendInterimSnapshot, disableInterim]);

  useEffect(() => {
    return () => {
      if (recorderRef.current) {
        try {
          recorderRef.current.cancelRecording();
          recorderRef.current.cleanup();
        } catch {
          // ignore cleanup errors
        }
      }
    };
  }, []);

  const stream = recorderRef.current?.getStream?.();

  return children({
    isRecording,
    loading,
    error,
    stream,
    recognized,
    toggleRecording,
  });
}

export default VoiceRecorder;
